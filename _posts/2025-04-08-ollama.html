---
layout: post
title: "Getting started with Ollama"
subtitle: "...or how I learned something new today."
date: 2025-05-05 14:00:00 -0400
background: '/img/posts/01.jpg'
tags: [python, ollama, chatbot, copilot, tinkering]
---

<p><em>Every now and then, a video pops up in your feed and makes you think, “Yeah, I could totally do that.”</em> That’s exactly what happened when I stumbled on <a href="https://www.youtube.com/watch?v=your-link-here" target="_blank">this tutorial</a>: <strong>Create a LOCAL Python AI Chatbot In Minutes Using Ollama</strong>. I clicked. I watched. I dove in.</p>

<p>Now, I’ve always liked understanding what’s going on <em>behind the scenes</em>, so spinning up a local LLM seemed like a great excuse to get my hands dirty.</p>

<img src="/img/llamma.png" alt="Cartoon llama coding at a desk" style="width: 100%; max-width: 600px; margin: 20px auto; display: block; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" />

<p>Fast forward a few installations — Python, MS Code, Ollama, and a few miscellaneous bits — and I actually had a private LLM running on my machine. Locally. As in: not in the cloud, not through some third-party API, but right here on my own humble PC (which I am now slightly regretting not upgrading — hindsight, meet wallet).</p>

<p><strong>Did I learn something?</strong> Sort of. Let’s say I could <em>mostly</em> follow the code. Baby steps.</p>

<p>The trickiest part? GitHub Copilot. Oh, Copilot. It kept trying to "help" by suggesting its own takes on the code — often <em>almost</em> what I needed, but just different enough to trip me up. I get that it’s trying to be helpful, but it definitely added a few bonus puzzles to the mix.</p>

<p>Still, I came away fascinated. Seeing how much Copilot can do — especially for someone who doesn’t live and breathe code — is wild. Tomorrow, I might dig a bit deeper to make it even more responsive to my prompts. For now, I’ll call it a small win.</p>
